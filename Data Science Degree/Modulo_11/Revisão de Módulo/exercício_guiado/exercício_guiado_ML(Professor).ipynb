{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c113df45",
   "metadata": {},
   "source": [
    "# Exercício guiado de Machine Learning\n",
    "\n",
    "## Advanced analytics no mercado de vinho\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f11943",
   "metadata": {},
   "source": [
    "Suponha que você é um cientista de dados que trabalha na área de *advanced analytics* de uma empresa especializada na distribuição e vendas de vinhos tintos. Naturalmente, a empresa está interessada em vender vinhos que sejam percebidos como bons por grande parte do público. Pensando nisso, foi feita uma pesquisa, na qual vinhos tintos com diferentes características físico-químicas foram oferecidos a alguns voluntários, que, após experimentá-los, deram notas de 0 a 10. A base coletada contém as seguintes informações:\n",
    "\n",
    "- Medidas de 11 variáveis físico-químicas que caracterizam cada amostra (as features do problema):\n",
    "<br><br>\n",
    "    - 1 - fixed acidity - medida da acidez devido à presença de ácidos orgânicos de baixa volatilidade (ácido málico, lático, tartárico ou cítrico) no vinho;\n",
    "    - 2 - volatile acidity - medida da acidez devido a ácidos de baixo peso molecular (sobretudo ácido acético) presentes no vinho, que são responsáveis pelo aroma e gosto de vinagre;\n",
    "    - 3 - citric acid - medida de ácido cítrico no vinho;\n",
    "    - 4 - residual sugar - medida de açúcar residual presente no vinho, com origem nos resíduos de açúcar da uva que permanecem no vinho após o fim da fermentação;\n",
    "    - 5 - chlorides - medida de cloretos (íons de cloro) no vinho;\n",
    "    - 6 - free sulfur dioxide - medida de dióxido de enxofre livre (isto é, que não está ligado a outras moléculas) no vinho;\n",
    "    - 7 - total sulfur dioxide - medida de dióxido de enxofre total (livre + porção ligada a outras moléculas) no vinho;\n",
    "    - 8 - density - medida da densidade do vinho;\n",
    "    - 9 - pH - medida do pH do vinho;\n",
    "    - 10 - sulphates - medida de sulfatos (íons SO₄²⁻) no vinho;\n",
    "    - 11 - alcohol - medida da graduação alcoólica do vinho.\n",
    "<br><br>\n",
    "- Além disso, há a variável resposta que no caso é um score numérico:\n",
    "<br><br>\n",
    "    - 12 - quality - score numérico de qualidade (de 0 a 10), produzido com base em dados sensoriais.\n",
    "\n",
    "Com base nestes dados coletados, seu objetivo é produzir um modelo capaz de distinguir vinhos bons de ruins, com base nas medidas de suas características físico-químicas. \n",
    "\n",
    "Uma vez que tenhamos este modelo, caso produtoras de vinho ofereçam um novo vinho para ser vendido por sua empresa, será possível decidir de maneira mais direcionada se vale a pena passar a vender este produto ou não, de acordo com a predição de sua qualidade dada pelo modelo.\n",
    "\n",
    "Dentro deste contexto, seu objetivo como cientista de dados é claro:\n",
    "\n",
    "> Agregar valor ao negócio, explorando os dados que você tem à disposição.\n",
    "\n",
    "Na primeira sprint do projeto, você e outros colegas do time de ciência de dados chegaram na seguinte _TO-DO list_ para o desenvolvimento do projeto:\n",
    "\n",
    "- [ ] Ingestão dos dados e detalhada análise exploratória\n",
    "- [ ] Formulação do problema\n",
    "- [ ] Primeiro modelo baseline\n",
    "- [ ] Iterações pelo ciclo de modelagem\n",
    "- [ ] Compilação dos resultados para o negócio\n",
    "- [ ] Comunicação dos resultados\n",
    "\n",
    "Com base na TO-DO list acima, o time de data science quebrou a análise exploratória em algumas perguntas importantes a serem respondidas, antes da etapa de modelagem.\n",
    "\n",
    "Agora é com você! Bom trabalho, e divirta-se! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dba3cd",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "*Obs.: Naturalmente, o enunciado acima foi apenas uma historinha que criei pra motivar o problema em um contexto de negócio, rs. Para maiores informações sobre a coleta e origem real dos dados, veja a página do dataset no repositório UCI machine learning repository, [disponível aqui!](https://archive.ics.uci.edu/ml/datasets/wine+quality)* \n",
    "\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df86b5",
   "metadata": {},
   "source": [
    "Vamos começar pelos primeiros pontos da TO-DO list:\n",
    "\n",
    "- [ ] Ingestão dos dados e detalhada análise exploratória\n",
    "- [ ] Formulação do problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f36247",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2251e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:01.883269Z",
     "start_time": "2022-09-01T00:31:56.858241Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899cb3d2",
   "metadata": {},
   "source": [
    "1) Leia o arquivo csv `winequality-red.csv`, construindo um Data Frame do pandas. Responda:\n",
    "\n",
    "- Quantas linhas há no dataset?\n",
    "- Quantas colunas há no dataset?\n",
    "- Quais os tipos de dados em cada coluna?\n",
    "- Há dados nulos (null, missing) na base?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64045e45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:01.959226Z",
     "start_time": "2022-09-01T00:32:01.891269Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92db611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:02.067410Z",
     "start_time": "2022-09-01T00:32:01.965223Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f282e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:02.221835Z",
     "start_time": "2022-09-01T00:32:02.072408Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b8972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:02.376780Z",
     "start_time": "2022-09-01T00:32:02.228832Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be9c5d",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4790054",
   "metadata": {},
   "source": [
    "### Observação importante!\n",
    "\n",
    "A primeira EDA pode ser feita com toda a amostra de dados que temos disponível, sem problemas.\n",
    "\n",
    "No entanto, a partir do momento em que chegamos à conclusão de que de fato é necessário construir um modelo, é importante que façamos o **train-test split**, e:\n",
    "\n",
    ">**Qualquer análise exploratória que, de qualquer maneira, guie o processo de construção do modelo, deve ser feita únicamente com os dados de treino!!**\n",
    "\n",
    "Isso é importante porque, lembre-se, a base de teste tem o único propósito de nos auxiliar a estimar a performance de generalização de nosso modelo, e não deve ser usada em hipótese alguma no passo 1 (construção do modelo), pois se isso acontecer, estaremos cometendo data leakage, e a estimativa de generalização pode se invalidar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9f58c",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d547fc",
   "metadata": {},
   "source": [
    "2) Utilizando a base de vinhos tintos, estude a distribuição das variáveis numéricas, calculando, para cada coluna, as principais estatísticas descritivas de posição (média, mediana, quartis, etc.) e de dispersão (std, IQR, etc.). Se desejar, visualize as distribuições de cada variável na amostra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283ff0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:02.595657Z",
     "start_time": "2022-09-01T00:32:02.381778Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49df12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:08.556524Z",
     "start_time": "2022-09-01T00:32:02.600652Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df:\n",
    "\n",
    "    sns.histplot(data=df, x=col, kde=True).set_title(f\"Distribuição da variável {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a34481",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b9721",
   "metadata": {},
   "source": [
    "3) Utilizando a base de vinhos tintos, responda: existe alguma coluna com outliers? Indique qual método de detecção de outliers você utilizou, justificando seu uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e8dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:08.603498Z",
     "start_time": "2022-09-01T00:32:08.565520Z"
    }
   },
   "outputs": [],
   "source": [
    "col = \"alcohol\"\n",
    "\n",
    "mu, std = df[col].mean(), df[col].std()\n",
    "\n",
    "# será outlier se |z| > 3\n",
    "aux_outliers = df[col].apply(lambda x: (x - mu)/std).apply(lambda x: np.abs(x) > 3)\n",
    "\n",
    "# outra opção, com sintaxe um pouco maior, mas talvez mais clara\n",
    "# df[col].apply(lambda x: (x - mu)/std).apply(lambda x: True if np.abs(x) > 3 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9579b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:08.742360Z",
     "start_time": "2022-09-01T00:32:08.617488Z"
    }
   },
   "outputs": [],
   "source": [
    "aux_outliers.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c5981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:08.866109Z",
     "start_time": "2022-09-01T00:32:08.752354Z"
    }
   },
   "outputs": [],
   "source": [
    "# isto retorna apenas as linhas em que eu tenho valor \"True\", isso é, os outliers\n",
    "\n",
    "aux_outliers[aux_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dff7f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:08.974049Z",
     "start_time": "2022-09-01T00:32:08.880102Z"
    }
   },
   "outputs": [],
   "source": [
    "indices_outliers = aux_outliers[aux_outliers].index.tolist()\n",
    "\n",
    "indices_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac947910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:09.237808Z",
     "start_time": "2022-09-01T00:32:08.983044Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[indices_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2088d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:09.516651Z",
     "start_time": "2022-09-01T00:32:09.244806Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# colocando tudo numa única célula\n",
    "\n",
    "# dropando o target, pq só quero analisar as features\n",
    "for col in df.drop(columns=\"quality\"):\n",
    "    \n",
    "    mu, std = df[col].mean(), df[col].std()\n",
    "\n",
    "    # será outlier se |z| > 3\n",
    "    aux_outliers = df[col].apply(lambda x: (x - mu)/std).apply(lambda x: np.abs(x) > 3)\n",
    "    \n",
    "    indices_outliers = aux_outliers[aux_outliers].index.tolist()\n",
    "\n",
    "    if len(indices_outliers) >= 1:\n",
    "        \n",
    "        print(f\"A coluna {col} tem {len(indices_outliers)} outliers!\")\n",
    "        print(\"\\nOs índices deles são:\\n\")\n",
    "        print(indices_outliers)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(f\"A coluna {col} não tem outliers!\")\n",
    "        \n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ef8a2",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e1e2a",
   "metadata": {},
   "source": [
    "4) Utilizando a base de vinhos tintos, estude os dados na coluna `quality`, que é a variável resposta do problema. Em particular, responda:\n",
    "\n",
    "- Essa é uma variável contínua ou discreta?\n",
    "- Como as notas estão distribuídas? Quais as notas mais/menos comuns?\n",
    "- Faz sentido discretizar esta variável em dois níveis categóricos? \n",
    "    - Se sim, qual seria o valor de corte, e, com este corte, qual é o significado de cada nível categórico?\n",
    "    - Como estes dois níveis categóricos estão distribuídos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c868cc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:09.577619Z",
     "start_time": "2022-09-01T00:32:09.524645Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6b327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:10.658741Z",
     "start_time": "2022-09-01T00:32:09.582612Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"quality\", kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f86744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:10.688725Z",
     "start_time": "2022-09-01T00:32:10.665737Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0a78e",
   "metadata": {},
   "source": [
    "> Conclusão depois da conversa com negócio 15/08: de fato, eles esperam como resposta uma decisão binária. Por isso, decidimos seguir como um problema de classificação binária!\n",
    "\n",
    "> Pergunta: como discretizar as notas? Ou seja, quais serão as duas classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a14284",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89defa",
   "metadata": {},
   "source": [
    "5) Utilizando a base de vinhos tintos, calcule e/ou visualize a correlação (utilizando a relação que achar mais adequada) entre as variáveis na base. \n",
    "\n",
    "Em particular, estude a correlação entre as features e o target `quality`, e responda se há correlações fortes.\n",
    "\n",
    "Plote também a relação entre cada uma das features e o target (na forma de um scatterplot, por exemplo).\n",
    "\n",
    "Com base nas análises acima, responda: é uma boa ideia modelar o problema como um problema de regressão? Se sim, que métodos de aprendizagem você utilizaria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d97cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:10.905465Z",
     "start_time": "2022-09-01T00:32:10.695720Z"
    }
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d56f8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:13.466192Z",
     "start_time": "2022-09-01T00:32:10.912460Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07082f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:13.496176Z",
     "start_time": "2022-09-01T00:32:13.472189Z"
    }
   },
   "outputs": [],
   "source": [
    "df.corr()[\"quality\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dc34b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:15.096677Z",
     "start_time": "2022-09-01T00:32:13.501173Z"
    }
   },
   "outputs": [],
   "source": [
    "col=\"alcohol\"\n",
    "\n",
    "sns.jointplot(data=df, x=col, y=\"quality\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a4bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:29.930615Z",
     "start_time": "2022-09-01T00:32:15.104673Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df.drop(columns=\"quality\"):\n",
    "    \n",
    "    sns.jointplot(data=df, x=col, y=\"quality\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3ac7b",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97d73d",
   "metadata": {},
   "source": [
    "6) Utilizando a base de vinhos tintos, calcule e/ou visualize (em um gráfico de barras, ou como preferir) o intervalo de confiança de 90% para a média de cada uma das variáveis físico-químicas, agrupadas pelos níveis categóricos da variável resposta `quality`. Que conclusões são possíveis tirar destes gráficos?\n",
    "\n",
    "Sugestão: utilizar o seaborn para a visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b8f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:37.526397Z",
     "start_time": "2022-09-01T00:32:29.936613Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df.drop(columns=\"quality\"):\n",
    "    \n",
    "    sns.barplot(data=df, x=\"quality\", y=col, ci=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57950ae",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec87039",
   "metadata": {},
   "source": [
    "7) Utilizando a base de vinhos tintos, discretize a variável resposta `quality` em dois níveis categóricos para transformar o problema em um problema de classificação binária. Como valor de corte, utilize aquele que seja tal que os dois níveis categóricos estejam o mais igualmente distribuídos possível (isto é, um corte que minimize o desbalanceamento das classes). Sugestão: teste todos os valores de corte possíveis (não são muitos!)\n",
    "\n",
    "Após a determinação do valor de corte que satisfaça às condições acima, responda: o que, qualitativamente, cada uma das duas classes representa? Esta discretização faz sentido? Se sim, para facilitar análises posteriores, nomeie as classes de acordo.\n",
    "\n",
    "Dica: vamos usar esta nova variável resposta binária nas análises dos próximos exercícios, então sugiro que o dataframe com esta variável seja salvo num arquivo, para que ele possa ser simplesmente lido posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206dfba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:37.570349Z",
     "start_time": "2022-09-01T00:32:37.552362Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"quality\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad319156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:39.392107Z",
     "start_time": "2022-09-01T00:32:37.583342Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for corte in df[\"quality\"].sort_values().unique():\n",
    "\n",
    "    print(f\"\\nDistribuição de classes pra corte em nota = {corte}\")\n",
    "\n",
    "    aux_bin = df[\"quality\"].apply(lambda x: \"bom\" if x > corte else \"ruim\")\n",
    "\n",
    "    print(aux_bin.value_counts())\n",
    "    print()\n",
    "    print(aux_bin.value_counts(normalize=True)*100)\n",
    "\n",
    "    sns.countplot(x=aux_bin)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cce4ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:39.424090Z",
     "start_time": "2022-09-01T00:32:39.398104Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"quality_bin\"] = df[\"quality\"].apply(lambda x: \"bom\" if x > 5 else \"ruim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d44d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:39.565018Z",
     "start_time": "2022-09-01T00:32:39.434085Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbd403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:39.735921Z",
     "start_time": "2022-09-01T00:32:39.568018Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bin = df.drop(columns=[\"quality\"])\n",
    "\n",
    "df_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed8817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:40.022293Z",
     "start_time": "2022-09-01T00:32:39.745916Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bin.to_csv(\"winequality-red-binary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e434a",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7587c49",
   "metadata": {},
   "source": [
    "> Na úlitma conversa com o negócio, ficou alinhado de que vamos seguir com a classificação.\n",
    "\n",
    "> Agora vamos começar a pensar em modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4aca46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:40.062271Z",
     "start_time": "2022-09-01T00:32:40.034308Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_bin.drop(columns=\"quality_bin\")\n",
    "y = df_bin[\"quality_bin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b1443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:40.281145Z",
     "start_time": "2022-09-01T00:32:40.081259Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745caddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:40.419614Z",
     "start_time": "2022-09-01T00:32:40.288141Z"
    }
   },
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28b47c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:41.219288Z",
     "start_time": "2022-09-01T00:32:40.424612Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b11cef9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:41.281494Z",
     "start_time": "2022-09-01T00:32:41.222528Z"
    }
   },
   "outputs": [],
   "source": [
    "# aqui, eu junto as features e o target de novo só pra facilitar em alguns procedimentos\n",
    "\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3e382a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:41.375441Z",
     "start_time": "2022-09-01T00:32:41.285493Z"
    }
   },
   "outputs": [],
   "source": [
    "# isso vai pra gaveta!\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc97f91",
   "metadata": {},
   "source": [
    "8) Considere a base de vinhos tintos com a variável `quality` discretizada em duas classes (\"good\" para score maior que 5; \"bad\" caso contrário). Vamos agora analisar a separabilidade das duas classes do problema. Para isso, faça:\n",
    "\n",
    "- Visualize as distribuições das features, com indicação dos diferentes níveis categóricos do target;\n",
    "- Visualize as projeções dos dados em cada um dos subespaços de pares de features, com indicação dos níveis categóricos do target;\n",
    "\n",
    "Responda: com base nesta análise, o problema é linearmente separável?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b6c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:32:50.124924Z",
     "start_time": "2022-09-01T00:32:41.383438Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in X_train:\n",
    "\n",
    "    sns.histplot(data=X_train, x=col, kde=True, hue=y_train).set_title(f\"Distribuição da variável {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe17780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:16.695010Z",
     "start_time": "2022-09-01T00:32:50.127924Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_train, hue=\"quality_bin\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c80acfd",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954f31a",
   "metadata": {},
   "source": [
    "9) Considere a base de vinhos tintos com a variável `quality` discretizada em duas classes (\"good\" para score maior que 5; \"bad\" caso contrário). Separe o dataset em dados de treino (70%) e de teste (30%), estratifidando pelo target. Utilize `random_state=42` como seed, para fins de reprodutibilidade.\n",
    "\n",
    "Apenas com os dados de treino, calcule as componentes principais do espaço de features, e responda:\n",
    "\n",
    "- Quantas componentes principais são necessárias para que pelo menos 90% da variância do dataset seja explicada?\n",
    "- Faça um scatterplot das duas primeiras componentes principais, com indicação dos níveis categóricos do target;\n",
    "    - No sub-espaço das duas primeiras componentes principais, há separabilidade linear dos dados?\n",
    "\n",
    "Dica: utilize as ferramentas do scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf82ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:16.894885Z",
     "start_time": "2022-09-01T00:34:16.700997Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440854a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:16.940859Z",
     "start_time": "2022-09-01T00:34:16.897883Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_pca = Pipeline([(\"ss\", StandardScaler()), \n",
    "                     (\"pca\", PCA())])\n",
    "\n",
    "pipe_pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c1282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:17.048311Z",
     "start_time": "2022-09-01T00:34:16.947861Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_pca[\"pca\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b9bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:17.203654Z",
     "start_time": "2022-09-01T00:34:17.055305Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_pca[\"pca\"].components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d381ee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:17.343573Z",
     "start_time": "2022-09-01T00:34:17.222643Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_pca[\"pca\"].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec7e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:17.483497Z",
     "start_time": "2022-09-01T00:34:17.353567Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_pca[\"pca\"].explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1da9aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:17.637405Z",
     "start_time": "2022-09-01T00:34:17.489489Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60045723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:17.808527Z",
     "start_time": "2022-09-01T00:34:17.641412Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_pca = pd.DataFrame(pipe_pca.transform(X_train), \n",
    "                           columns=[f\"PC{i+1}\" for i in range(X_train.shape[1])], \n",
    "                           index=X_train.index)\n",
    "\n",
    "X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ac641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:17.916467Z",
     "start_time": "2022-09-01T00:34:17.814525Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_pca[\"PC1 PC2\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0e452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:19.245673Z",
     "start_time": "2022-09-01T00:34:17.924462Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=X_train_pca, x=\"PC1\", y=\"PC2\", hue=y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45675c4",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d51fa0",
   "metadata": {},
   "source": [
    "10) Considere a base de vinhos tintos com a variável `quality` discretizada em duas classes (\"good\" para score maior que 5; \"bad\" caso contrário). Separe o dataset em dados de treino (70%) e de teste (30%), estratifidando pelo target. Utilize `random_state=42` como seed, para fins de reprodutibilidade. Usando os dados de treino, faça:\n",
    "\n",
    "- Agrupe os dados pelos níveis categóricos do target, e calcule a média de cada uma das features;\n",
    "\n",
    "- Faça um teste de hipótese para determinar se, a um nível de significância de 5%, há diferença na média de cada uma das sub-amostras de cada classe, para todas as variáveis;\n",
    "\n",
    "- Compare a distribuição das features analisando o boxplot de cada uma, separados pelas duas classes do target.\n",
    "\n",
    "Dica: utilize as ferramentas do scipy e do scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d16941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:19.322634Z",
     "start_time": "2022-09-01T00:34:19.251669Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.groupby(\"quality_bin\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6547dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:19.481537Z",
     "start_time": "2022-09-01T00:34:19.332623Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.groupby(\"quality_bin\").var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd07e669",
   "metadata": {},
   "source": [
    "Pro teste de hipótese, vamos usar a função [ttest_ind](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind) do scipy.stats!\n",
    "\n",
    "Faremos um teste t de Welch (não assumiremos variância populacional igual)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ecdaf",
   "metadata": {},
   "source": [
    "O teste que faremos será:\n",
    "\n",
    "> $H_0: \\ \\mu_1 = \\mu_2$\n",
    "\n",
    "> $H_1: \\ \\mu_1 \\neq \\mu_2$\n",
    "\n",
    "Que pode ser reescrito como:\n",
    "\n",
    "> $H_0: \\ \\mu_1 - \\mu_2 = 0$\n",
    "\n",
    "> $H_1: \\ \\mu_1 - \\mu_2 \\neq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9096cf",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "Entendendo o que é feito no bloco de código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff341492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:19.570485Z",
     "start_time": "2022-09-01T00:34:19.489532Z"
    }
   },
   "outputs": [],
   "source": [
    "vinhos_bons = df_train.query(\"quality_bin == 'bom'\")\n",
    "\n",
    "vinhos_ruins = df_train.query(\"quality_bin == 'ruim'\")\n",
    "\n",
    "# o que fizemos acima com o query é equivalente a isso:\n",
    "# vinhos_bons = df_train[df_train[\"quality_bin\"] == \"bom\"]\n",
    "# vinhos_ruins = df_train[df_train[\"quality_bin\"] == \"ruim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5cb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:19.677435Z",
     "start_time": "2022-09-01T00:34:19.576485Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df037e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:19.774437Z",
     "start_time": "2022-09-01T00:34:19.682434Z"
    }
   },
   "outputs": [],
   "source": [
    "col = \"fixed acidity\"\n",
    "\n",
    "t, p = ttest_ind(vinhos_bons[col].values, vinhos_ruins[col].values, alternative='two-sided')\n",
    "\n",
    "print(t, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9e8f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:19.879366Z",
     "start_time": "2022-09-01T00:34:19.782420Z"
    }
   },
   "outputs": [],
   "source": [
    "col = \"fixed acidity\"\n",
    "\n",
    "t, p = ttest_ind(vinhos_bons[col].values, vinhos_ruins[col].values, alternative='two-sided', equal_var=False)\n",
    "\n",
    "print(t, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4889476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:20.019283Z",
     "start_time": "2022-09-01T00:34:19.883362Z"
    }
   },
   "outputs": [],
   "source": [
    "sig = 0.05\n",
    "\n",
    "if p > sig:\n",
    "    print(\"Falha em rejeitar H0: não posso dizer que as médias são diferentes. Ou seja, não há indicios de separabilidade\")\n",
    "else:\n",
    "    print(\"Rejeita H0: as médias são diferentes!!! Ou seja, indício de separabilidade das classes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4711da1",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003024a8",
   "metadata": {},
   "source": [
    "Bloco de código pro teste de hipótese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0334aff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:20.157716Z",
     "start_time": "2022-09-01T00:34:20.030277Z"
    }
   },
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    OKGREEN = '\\033[92m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c4fcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:20.743816Z",
     "start_time": "2022-09-01T00:34:20.161714Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df_train, x=col, hue=\"quality_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d85d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:31.258536Z",
     "start_time": "2022-09-01T00:34:20.747815Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# alpha de 5%\n",
    "significancia = 0.05\n",
    "    \n",
    "# subpops de cada classe\n",
    "bad_subpop = df_train.query(\"quality_bin == 'ruim'\")\n",
    "good_subpop = df_train.query(\"quality_bin == 'bom'\")\n",
    "\n",
    "for col in df_train.drop(columns=\"quality_bin\"):\n",
    "    \n",
    "    print(f\"Para a distribuição da feature {col}, temos:\\n\")\n",
    "    \n",
    "    t, p_value = ttest_ind(good_subpop[col].values, bad_subpop[col].values, alternative=\"two-sided\", equal_var=False)\n",
    "    \n",
    "    print(f\"t-statistic: {t:.2f}; p-value: {p_value:.2e}\\n\")\n",
    "    \n",
    "    if p_value > significancia:\n",
    "        \n",
    "        str_fail = f\"{bcolors.FAIL}{bcolors.BOLD}\"\n",
    "        str_fail += \"Falha em rejeitar H_0: \"\n",
    "        str_fail += f\"parece que não há diferença na média de '{col}' em cada uma das sub-amostras 'good' e 'bad'!!\"\n",
    "        str_fail += f\"{bcolors.ENDC}\"\n",
    "        \n",
    "        print(str_fail)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        str_rej = f\"{bcolors.OKGREEN}{bcolors.BOLD}\"\n",
    "        str_rej += \"Rejeição da H_0: \"\n",
    "        str_rej += f\"há diferença na média de '{col}' em cada uma das sub-amostras 'good' e 'bad'!\"\n",
    "        str_rej += f\"{bcolors.ENDC}\"\n",
    "    \n",
    "        print(str_rej)\n",
    "        \n",
    "    # =======================================\n",
    "    \n",
    "    sns.kdeplot(data=df_train, x=col, hue=\"quality_bin\")\n",
    "    \n",
    "    # calculando as médias amostrais de cada subpop\n",
    "    mu_good, mu_bad = good_subpop[col].mean(), bad_subpop[col].mean()\n",
    "        \n",
    "    # \"C0\" é o azul padrão de primeira cor; \"C1\" é o laranja padrão de segunda cor\n",
    "    plt.axvline(x=mu_bad, color=\"C0\", label=r\"$\\bar{\\mu}_{ruim}=$\"+f\"{mu_bad:.2f}\", ls=\":\")\n",
    "    plt.axvline(x=mu_good, color=\"C1\", label=r\"$\\bar{\\mu}_{bom}=$\"+f\"{mu_good:.2f}\", ls=\":\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # =======================================\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5bba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:31.274526Z",
     "start_time": "2022-09-01T00:34:31.262532Z"
    }
   },
   "outputs": [],
   "source": [
    "str_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15512213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:31.413447Z",
     "start_time": "2022-09-01T00:34:31.281521Z"
    }
   },
   "outputs": [],
   "source": [
    "str_rej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73db91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:34.472219Z",
     "start_time": "2022-09-01T00:34:31.421448Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df_train.drop(columns=\"quality_bin\"):\n",
    "    \n",
    "    sns.boxplot(data=df_train, x=col, y=\"quality_bin\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef27f74",
   "metadata": {},
   "source": [
    "Conclusão: temos um problema de classificação cujas classes não são trivialmente separadas!\n",
    "\n",
    "Reunião com negócio, alinhamos dois pontos:\n",
    "\n",
    "- 1°: expectativas quanto à performance do modelo, dada a dificuldade do problema;\n",
    "\n",
    "- 2°: deixamos aberta a porta e criamos a \"curiosidade\" por parte do negócio de saber sobre a performance do modelo.\n",
    "\n",
    "Avisamos pro negócio. Expectativas alinhadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf7c73",
   "metadata": {},
   "source": [
    "__________\n",
    "__________\n",
    "__________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e261e54",
   "metadata": {},
   "source": [
    "Uma vez que você tenha respondido às questões anteriores, você completou, talvez sem perceber, o importantíssimo (e longo!) processo de análise exploratória dos dados (EDA, do termo inglês _exploratory data analysis_)!\n",
    "\n",
    "De fato, a etapa de EDA é importantíssima em todo projeto de ciência de dados, pois é apenas explorando os dados que de fato nos familiarizamos com o contexto do problema com o qual estamos trabalhando, o que é fundamental para o sucesso das próximas etapas, que pode envolver a criação e avaliação de modelos de machine learning, que é exatamente o que faremos agora, endereçando os próximos pontos da TO-DO list:\n",
    "\n",
    "- [ ] Primeiro modelo baseline\n",
    "- [ ] Iterações pelo ciclo de modelagem\n",
    "\n",
    "Vamos lá!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43658217",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784ab6c",
   "metadata": {},
   "source": [
    "### Passo 1 - Construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d1673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:34.488210Z",
     "start_time": "2022-09-01T00:34:34.479215Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b0d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:34.657490Z",
     "start_time": "2022-09-01T00:34:34.504199Z"
    }
   },
   "outputs": [],
   "source": [
    "# modelo baseline, usamos os hiperparametros com valores default!\n",
    "pipe_logit = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                       (\"logit\", LogisticRegression())])\n",
    "\n",
    "pipe_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6471e3",
   "metadata": {},
   "source": [
    "### Passo 2 - Avaliação do modelo\n",
    "\n",
    "# Avaliação da generalização do modelo!\n",
    "\n",
    "### Avaliar onde estamos no tradeoff viés-variância (sobretudo no caso de alta variância (overfit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261856d1",
   "metadata": {},
   "source": [
    "<img src=\"https://estatsite.com.br/wp-content/uploads/2020/07/bias-variance-tradeoff.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e57896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:34.735342Z",
     "start_time": "2022-09-01T00:34:34.663489Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091356a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:34.858816Z",
     "start_time": "2022-09-01T00:34:34.740340Z"
    }
   },
   "outputs": [],
   "source": [
    "def clf_metrics(modelo, X, y_true, label, plot_conf_mat=True):\n",
    "    \n",
    "    print(f\"\\nMétricas de avaliação de {label}:\\n\")\n",
    "    \n",
    "    y_pred = modelo.predict(X)\n",
    "\n",
    "    if plot_conf_mat:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, ax=ax[0]) \n",
    "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, normalize=\"all\", ax=ax[1])\n",
    "        plt.show()\n",
    "\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235de06",
   "metadata": {},
   "source": [
    "Conforme falamos em aula, é importante que calculemos as métricas de avaliação tanto na base de treino quanto na base de teste, pra aferir se o modelo está overfitado (isto é, aferir a variância):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bf773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:35.075096Z",
     "start_time": "2022-09-01T00:34:34.862801Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_metrics(pipe_logit, X_train, y_train, \"treino\", plot_conf_mat=False)\n",
    "print(\"#\"*80)\n",
    "clf_metrics(pipe_logit, X_test, y_test, \"teste\", plot_conf_mat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc98eb",
   "metadata": {},
   "source": [
    "Este modelo, no caso, sofre de underfitting (o que faz sentido, dado que a regressão logística (um modelo linear) é demasiadamente simples para os nossos dados!).\n",
    "\n",
    "Como baseline, funciona muito bem. \n",
    "\n",
    "Nosso objetivo agora vai ser melhorar esta performance, aumentando um pouco a complexidadce da hipótese!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dded00",
   "metadata": {},
   "source": [
    "## Agora, vamos entrar no ciclo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee56e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:36.495780Z",
     "start_time": "2022-09-01T00:34:35.081091Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ================================\n",
    "# Passo 1\n",
    "\n",
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"dt\", RandomForestClassifier())])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "# Passo 2\n",
    "\n",
    "clf_metrics(pipe_rf, X_train, y_train, \"treino\", plot_conf_mat=False)\n",
    "print(\"#\"*80)\n",
    "clf_metrics(pipe_rf, X_test, y_test, \"teste\", plot_conf_mat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9061c91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:36.790951Z",
     "start_time": "2022-09-01T00:34:36.518768Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ================================\n",
    "# Passo 1\n",
    "\n",
    "pipe_dt = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"dt\", DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "pipe_dt.fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "# Passo 2\n",
    "\n",
    "clf_metrics(pipe_dt, X_train, y_train, \"treino\", plot_conf_mat=False)\n",
    "print(\"#\"*80)\n",
    "clf_metrics(pipe_dt, X_test, y_test, \"teste\", plot_conf_mat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee32e67",
   "metadata": {},
   "source": [
    "## CLARAMENTE TEMOS MODELOS OVERFITADOS!\n",
    "\n",
    "Por isso, **SEMPRE COMPARE AS MÉTRICAS DE TREINO COM O TESTE!**\n",
    "\n",
    "Identificar o overfitting é relativamente fácil:\n",
    "\n",
    "- Se tivermos um modelo perfeito na base de treino (erro 0, ou métricas de clf 1) - claramente overfitado, aprendeu até as particularidades da base de treino, deixou de conseguir generalizar!\n",
    "\n",
    "- Se não estiver perfeito no treino, ainda assim, avalie o **gap** (isto é, a **diferença** entre as métricas de treino e teste) -- se o gap for muito alto, é pq o modelo sofre de algum grau de overfitting.\n",
    "\n",
    "O ideal é que tenhamos um modelo que tenha um **pequeno gap** entre as métricas de treino e teste, e, que ambas sejam boas (com o trenho ligeiramente melhor que o teste). Isso é o que chamamos de \"sweet spot de generalização\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c1d21",
   "metadata": {},
   "source": [
    "Agora vamos continuar iterando no ciclo de modelagem, variando os algoritmos de aprendizagem e seus hiperparâmetros (sobretudo para controlar o balanço entre complexidade e simplicidade dos modelos!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87625e24",
   "metadata": {},
   "source": [
    "## Entrando no ciclo de modelagem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a899efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:36.835589Z",
     "start_time": "2022-09-01T00:34:36.795611Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pipe_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41734c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:37.007490Z",
     "start_time": "2022-09-01T00:34:36.846580Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befd997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:37.192926Z",
     "start_time": "2022-09-01T00:34:37.016483Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_report(y_test, y_pred, output_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56e020",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:37.350836Z",
     "start_time": "2022-09-01T00:34:37.197922Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_metricas = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "dict_metricas[\"weighted avg\"][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19e9da",
   "metadata": {},
   "source": [
    "A mesma função de antes, mas agora com o dicionário do classificarion report retornada, pra gente conseguir extrair as métricas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e70e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:37.478761Z",
     "start_time": "2022-09-01T00:34:37.356832Z"
    }
   },
   "outputs": [],
   "source": [
    "def clf_metrics_com_return(modelo, X, y_true, label, plot_conf_mat=True, print_cr=True):\n",
    "    \n",
    "    if print_cr:\n",
    "        print(f\"\\nMétricas de avaliação de {label}:\\n\")\n",
    "    \n",
    "    y_pred = modelo.predict(X)\n",
    "\n",
    "    if plot_conf_mat:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, ax=ax[0]) \n",
    "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, normalize=\"all\", ax=ax[1])\n",
    "        plt.show()\n",
    "\n",
    "    if print_cr:\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    return classification_report(y_true, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2c734",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:37.573488Z",
     "start_time": "2022-09-01T00:34:37.483759Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925872e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:39.197224Z",
     "start_time": "2022-09-01T00:34:37.576486Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_logit = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                       (\"logit\", LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_dt = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"dt\", DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                     (\"svm\", SVC(random_state=42))])\n",
    "\n",
    "# =======================================\n",
    "\n",
    "dict_pipes = {\"logit\" : pipe_logit,\n",
    "              \"random forest\" : pipe_rf,\n",
    "              \"decision tree\" : pipe_dt,\n",
    "              \"svm\" : pipe_svm}\n",
    "\n",
    "# =======================================\n",
    "# experimento!\n",
    "\n",
    "resultado_experimentos = {\"estimador\" : [],\n",
    "                          \"f1_treino\" : [],\n",
    "                          \"f1_teste\" : []}\n",
    "\n",
    "print_progress = False\n",
    "\n",
    "for label, pipe in dict_pipes.items():\n",
    "    \n",
    "    if print_progress:\n",
    "        print(\"\\n\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Estimador: {label}\".center(80))\n",
    "        print(\"(com hiperparâmetros default)\".center(80))\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # ================================\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # ================================\n",
    "    # Passo 2\n",
    "\n",
    "    dict_metricas_treino = clf_metrics_com_return(pipe, X_train, y_train, \"treino\", plot_conf_mat=False, print_cr=False)\n",
    "    \n",
    "    if print_progress:\n",
    "        print(\"#\"*80)\n",
    "        \n",
    "    dict_metricas_teste = clf_metrics_com_return(pipe, X_test, y_test, \"teste\", plot_conf_mat=False, print_cr=False)\n",
    "    \n",
    "    # pegar as métricas pra salvar abaixo!\n",
    "    f1_treino = dict_metricas_treino[\"weighted avg\"][\"f1-score\"]\n",
    "    f1_teste = dict_metricas_teste[\"weighted avg\"][\"f1-score\"]\n",
    "    \n",
    "    # ================================\n",
    "    # guardando os resultados do experimento\n",
    "    \n",
    "    resultado_experimentos[\"estimador\"].append(label)\n",
    "    resultado_experimentos[\"f1_treino\"].append(f1_treino)\n",
    "    resultado_experimentos[\"f1_teste\"].append(f1_teste)\n",
    "    \n",
    "    \n",
    "df_results = pd.DataFrame(resultado_experimentos)\n",
    "\n",
    "df_results[\"gap\"] = (df_results[\"f1_treino\"] - df_results[\"f1_teste\"]).apply(lambda x: x if x > 0 else np.inf)\n",
    "\n",
    "df_results = df_results.sort_values(\"f1_teste\", ascending=False).sort_values(\"gap\")\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51235b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:39.244196Z",
     "start_time": "2022-09-01T00:34:39.204222Z"
    }
   },
   "outputs": [],
   "source": [
    "def experimentos_ciclo_de_modelagem(dict_pipes, \n",
    "                                    plot_conf_mat=False, print_cr=False,\n",
    "                                    print_progress = False):\n",
    "    \n",
    "    resultado_experimentos = {\"estimador\" : [],\n",
    "                              \"f1_treino\" : [],\n",
    "                              \"f1_teste\" : []}\n",
    "\n",
    "    for label, pipe in dict_pipes.items():\n",
    "\n",
    "        if print_progress:\n",
    "            print(\"\\n\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"Estimador: {label}\".center(80))\n",
    "            print(\"(com hiperparâmetros default)\".center(80))\n",
    "            print(\"=\"*80)\n",
    "            print(\"\\n\")\n",
    "\n",
    "        # ================================\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        # ================================\n",
    "        # Passo 2\n",
    "\n",
    "        dict_metricas_treino = clf_metrics_com_return(pipe, X_train, y_train, \"treino\", \n",
    "                                                      plot_conf_mat=plot_conf_mat, print_cr=print_cr)\n",
    "\n",
    "        if print_progress:\n",
    "            print(\"#\"*80)\n",
    "\n",
    "        dict_metricas_teste = clf_metrics_com_return(pipe, X_test, y_test, \"teste\", \n",
    "                                                     plot_conf_mat=plot_conf_mat, print_cr=print_cr)\n",
    "\n",
    "        # pegar as métricas pra salvar abaixo!\n",
    "        f1_treino = dict_metricas_treino[\"weighted avg\"][\"f1-score\"]\n",
    "        f1_teste = dict_metricas_teste[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "        # ================================\n",
    "        # guardando os resultados do experimento\n",
    "\n",
    "        resultado_experimentos[\"estimador\"].append(label)\n",
    "        resultado_experimentos[\"f1_treino\"].append(f1_treino)\n",
    "        resultado_experimentos[\"f1_teste\"].append(f1_teste)\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame(resultado_experimentos)\n",
    "\n",
    "    df_results[\"gap\"] = (df_results[\"f1_treino\"] - df_results[\"f1_teste\"]).apply(lambda x: x if x > 0 else np.inf)\n",
    "\n",
    "    df_results = df_results.sort_values(\"f1_teste\", ascending=False).sort_values(\"gap\")\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038bd15b",
   "metadata": {},
   "source": [
    "___________\n",
    "\n",
    "Agora sim, tudo mais condensado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d294b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:42.795770Z",
     "start_time": "2022-09-01T00:34:39.249194Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef976b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:42.826767Z",
     "start_time": "2022-09-01T00:34:42.807765Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ee878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:46.134547Z",
     "start_time": "2022-09-01T00:34:42.848736Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_logit = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                       (\"logit\", LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_dt = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"dt\", DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                     (\"svm\", SVC(random_state=42))])\n",
    "\n",
    "pipe_xbgoost = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                         (\"xgboost\", XGBClassifier(random_state=42))])\n",
    "\n",
    "pipe_lgbm = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                      (\"lgbm\", LGBMClassifier(random_state=42))])\n",
    "\n",
    "pipe_knn = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                     (\"knn\", KNeighborsClassifier())])\n",
    "\n",
    "# =======================================\n",
    "\n",
    "dict_pipes = {\"logit\" : pipe_logit,\n",
    "              \"random_forest\" : pipe_rf,\n",
    "              \"decision_tree\" : pipe_dt,\n",
    "              \"svm\" : pipe_svm,\n",
    "              \"xgboost\" : pipe_xbgoost,\n",
    "              \"lgbm\" : pipe_lgbm,\n",
    "              \"knn\" : pipe_knn}\n",
    "\n",
    "# =======================================\n",
    "\n",
    "df_results = experimentos_ciclo_de_modelagem(dict_pipes, \n",
    "                                             plot_conf_mat=False, print_cr=False,\n",
    "                                             print_progress = False)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd820ce0",
   "metadata": {},
   "source": [
    "____________\n",
    "\n",
    "### Otimização de hiperparâmetros\n",
    "\n",
    "- Começo com um random search, pra identificar **regiões promissoras no espçao de hiperparâmetros**;\n",
    "\n",
    "- Depois de encontrar estas regiões promissoros, uso o grid search pra fazer um **ajuste fino** nas redondezas da região promissora.\n",
    "\n",
    "Tudo isso, se for relativamente rápido de passar pelos processos acima. \n",
    "\n",
    "Se demorar muito (é o caso, por exemplo, de bases muito grandes), parto direto pra otimização baeysiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67099eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:46.149538Z",
     "start_time": "2022-09-01T00:34:46.138545Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52791b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:46.274466Z",
     "start_time": "2022-09-01T00:34:46.154537Z"
    }
   },
   "outputs": [],
   "source": [
    "np.arange(100, 1501, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb882501",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:34:46.374296Z",
     "start_time": "2022-09-01T00:34:46.286460Z"
    }
   },
   "outputs": [],
   "source": [
    "np.arange(2, 9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616ca71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:46:24.559771Z",
     "start_time": "2022-09-01T00:41:59.658407Z"
    }
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(n_jobs=-1, random_state=42))])\n",
    "\n",
    "# espaço de hiperparâmetros \n",
    "# (esta definição vem do conhecimento que temos do método e de seus hiperparâmetros)\n",
    "params_distributions = {\"rf__n_estimators\" : np.arange(100, 1501, 1), \n",
    "                        \"rf__max_depth\" : np.arange(2, 9, 1)}\n",
    "\n",
    "# estratégia de cross validation \n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# montamos o objeto do random search\n",
    "rand_grid_rf = RandomizedSearchCV(pipe_rf, \n",
    "                                  params_distributions, \n",
    "                                  n_iter=20,\n",
    "                                  cv=splitter,\n",
    "                                  scoring=\"f1_weighted\",\n",
    "                                  verbose=10,\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=42,\n",
    "                                  return_train_score=True)\n",
    "\n",
    "rand_grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba315a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:46:24.756661Z",
     "start_time": "2022-09-01T00:46:24.565768Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(rand_grid_rf.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975715a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:48:17.049688Z",
     "start_time": "2022-09-01T00:48:17.031697Z"
    }
   },
   "outputs": [],
   "source": [
    "rand_grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d09fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:48:20.183580Z",
     "start_time": "2022-09-01T00:48:20.153076Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_best_params_delta(grid, peso_delta=0.5, print_deltas=False):\n",
    "    '''\n",
    "    to-do: docsting\n",
    "    \n",
    "    - grid: é um objeto gridsearch já fitado!\n",
    "    '''\n",
    "    \n",
    "    cv_results_df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "    aux = cv_results_df[['mean_train_score', 'mean_test_score']].copy()\n",
    "\n",
    "    # esse será nosso novo critério: comparando treino e teste!!!\n",
    "    # assim, evitamos overfitting!\n",
    "    aux[\"delta\"] = (aux[\"mean_train_score\"] - aux[\"mean_test_score\"]).abs()\n",
    "\n",
    "    # vamos normalizar tanto as métricas quanto o delta pro intervalo (0.1, 0.9)\n",
    "    # (nao deixei (0, 1) pra nao zerar as coisas)\n",
    "    # com isso, podemos tratar de maneira unificada tanto problemas de regressão quanto classificação\n",
    "    aux_norm = pd.DataFrame(MinMaxScaler((0.1, 0.9)).fit_transform(aux), \n",
    "                            columns=[f\"{x}_norm\" for x in aux.columns], index=aux.index)\n",
    "\n",
    "    # considere:\n",
    "    # - w: o peso que colocamos no delta (1-w, portanto, é o peso que colocamos na métrica de teste);\n",
    "    # - d: delta;\n",
    "    # - m: a métrica de teste;\n",
    "    # a métrica final, que é MAXIMIZADA, é a seguinte:\n",
    "    # (w*(1-d)) + ((1-w)*m)\n",
    "    # quero maximizar essa métrica final, com o objetivo de MAXIMIZAR métrica de teste e ao mesmo tempo o MINIMIZAR o delta\n",
    "    # pra esse fim, somo as duas contribuições, tomando a métrica em si, e o complementar do delta, ponderados respectivamente\n",
    "    # com isso, consigo um ponto de equilibrio legal!\n",
    "    aux_norm[\"metrica_criterio_final\"] = (peso_delta*(1-aux_norm[\"delta_norm\"])) + ((1-peso_delta)*aux_norm[\"mean_test_score_norm\"])\n",
    "\n",
    "    aux = pd.concat([aux, aux_norm], axis=1).sort_values(\"metrica_criterio_final\", ascending=False)\n",
    "    \n",
    "    if print_deltas:\n",
    "        display(aux)\n",
    "\n",
    "    # esse é o indice correspondente à melhor métrica de critério final\n",
    "    # (note que já ordenamos acima, então a melhor métrica é a primeira linha!)\n",
    "    num_combinacao_melhor_delta = aux.iloc[0, :].name\n",
    "\n",
    "    # isso dá os melhores parametros, segundo o critério do delta!!\n",
    "    best_params_delta = cv_results_df.loc[num_combinacao_melhor_delta, \"params\"]\n",
    "\n",
    "    return best_params_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650e461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:48:48.955092Z",
     "start_time": "2022-09-01T00:48:48.948096Z"
    }
   },
   "outputs": [],
   "source": [
    "rand_grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51246c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:53:17.648887Z",
     "start_time": "2022-09-01T00:53:17.624397Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier())]).set_params(**{'rf__n_estimators': 365, 'rf__max_depth': 7})\n",
    "\n",
    "pipe_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23170e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:55:03.606321Z",
     "start_time": "2022-09-01T00:55:01.100448Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(random_state=42))]).set_params(**{'rf__n_estimators': 365,\n",
    "                                                                                    'rf__max_depth': 7})\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "# Passo 2\n",
    "\n",
    "clf_metrics(pipe_rf, X_train, y_train, \"treino\", plot_conf_mat=False)\n",
    "print(\"#\"*80)\n",
    "clf_metrics(pipe_rf, X_test, y_test, \"teste\", plot_conf_mat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeba52b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:51:14.921370Z",
     "start_time": "2022-09-01T00:51:14.891387Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_best_params_delta(rand_grid_rf, peso_delta=0.5, print_deltas=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777c34d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T00:56:17.191179Z",
     "start_time": "2022-09-01T00:56:14.046066Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(random_state=42))]).set_params(**{'rf__n_estimators': 683, \n",
    "                                                                                    'rf__max_depth': 4})\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "# Passo 2\n",
    "\n",
    "clf_metrics(pipe_rf, X_train, y_train, \"treino\", plot_conf_mat=False)\n",
    "print(\"#\"*80)\n",
    "clf_metrics(pipe_rf, X_test, y_test, \"teste\", plot_conf_mat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5f294",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d6efbc",
   "metadata": {},
   "source": [
    "Podemos pegar essa região promissora que saiu do random search acima (`{'rf__n_estimators': 683, 'rf__max_depth': 4}`), e buscar com o grid search na vizinhança dela (um ajuste fino!)\n",
    "\n",
    "Veja que o grid search (que testa todas as combinações sistematicamente) já vai incluir os hiperparametros encontrados acima!\n",
    "\n",
    "Ou seja, só dá pra melhorar! Piorar não vai!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7c9c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T01:00:10.372035Z",
     "start_time": "2022-09-01T01:00:10.357023Z"
    }
   },
   "outputs": [],
   "source": [
    "list(range(683-3, 683+3+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03b633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T01:08:28.210992Z",
     "start_time": "2022-09-01T01:04:49.740239Z"
    }
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(n_jobs=-1, random_state=42))])\n",
    "\n",
    "# grade de hiperparâmetros na \"redondeza\" da região promissora encontrada acima!\n",
    "parameters_grid = {\"rf__n_estimators\" : range(683-3, 683+3+1), \n",
    "                   \"rf__max_depth\" : [3, 4, 5]}\n",
    "\n",
    "# estratégia de cross validation \n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# montamos o objeto do random search\n",
    "grid_rf = GridSearchCV(pipe_rf, \n",
    "                        parameters_grid, \n",
    "                        cv=splitter,\n",
    "                        scoring=\"f1_weighted\",\n",
    "                        verbose=10,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c2dc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T01:08:28.259964Z",
     "start_time": "2022-09-01T01:08:28.218988Z"
    }
   },
   "outputs": [],
   "source": [
    "# olhando só pra métrica de teste\n",
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a97b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T01:10:39.738645Z",
     "start_time": "2022-09-01T01:10:35.533533Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(random_state=42))]).set_params(**{'rf__max_depth': 5, \n",
    "                                                                                    'rf__n_estimators': 680})\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "# Passo 2\n",
    "\n",
    "clf_metrics(pipe_rf, X_train, y_train, \"treino\", plot_conf_mat=False)\n",
    "print(\"#\"*80)\n",
    "clf_metrics(pipe_rf, X_test, y_test, \"teste\", plot_conf_mat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12a917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T01:08:28.445557Z",
     "start_time": "2022-09-01T01:08:28.280952Z"
    }
   },
   "outputs": [],
   "source": [
    "# olhando tanto pro teste quanto pro delta\n",
    "calc_best_params_delta(grid_rf, peso_delta=0.5, print_deltas=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1312d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T01:11:39.465020Z",
     "start_time": "2022-09-01T01:11:35.359914Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                    (\"rf\", RandomForestClassifier(random_state=42))]).set_params(**{'rf__max_depth': 4, \n",
    "                                                                                    'rf__n_estimators': 680})\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# ================================\n",
    "# Passo 2\n",
    "\n",
    "clf_metrics(pipe_rf, X_train, y_train, \"treino\", plot_conf_mat=False)\n",
    "print(\"#\"*80)\n",
    "clf_metrics(pipe_rf, X_test, y_test, \"teste\", plot_conf_mat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8201f76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac2820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f9959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa69772",
   "metadata": {},
   "source": [
    "## Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c0c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f585d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc5d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef703c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T21:59:40.029791Z",
     "start_time": "2022-08-31T21:59:39.859886Z"
    }
   },
   "outputs": [],
   "source": [
    "# baseline e ciclo de modelagem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8ea09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T21:59:40.171706Z",
     "start_time": "2022-08-31T21:59:40.033785Z"
    }
   },
   "outputs": [],
   "source": [
    "# incluir PCA na pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513767e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T21:59:40.313625Z",
     "start_time": "2022-08-31T21:59:40.175704Z"
    }
   },
   "outputs": [],
   "source": [
    "# detalhar o gridsearch, montagem do espaço de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12ada8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T21:59:40.455545Z",
     "start_time": "2022-08-31T21:59:40.317627Z"
    }
   },
   "outputs": [],
   "source": [
    "# tradeoff precision-recall e cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cedec",
   "metadata": {},
   "source": [
    "__________\n",
    "__________\n",
    "__________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a013ff8",
   "metadata": {},
   "source": [
    "Agora que já passamos um bom tempo no ciclo de modelagem, e temos ótimos resultados, precisamos reportá-los para o negócio. Isto é, falta endereçar os dois últimos pontos da TO-DO list:\n",
    "\n",
    "- [ ] Compilação dos resultados para o negócio\n",
    "- [ ] Comunicação dos resultados\n",
    "\n",
    "Para isso, use e abuse de ferramentas de dataviz, faça uma apresentação no PPT, enfim, o que for necessário para passar a mensagem para o negócio de maneira efetiva e precisa. E, lembre-se, a equipe de negócio não é técnica, então trate de usar uma linguagem acessível e com o mínimo de tecnicalidades --- mas esteja preparado para perguntas técnicas (talvez com alguns slides ocultos no final da apresentação), pois nunca sabemos quando perguntas assim podem aparecer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad25fbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T21:59:40.596467Z",
     "start_time": "2022-08-31T21:59:40.459541Z"
    }
   },
   "outputs": [],
   "source": [
    "# comunicação de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7545d646",
   "metadata": {},
   "source": [
    "__________\n",
    "__________\n",
    "__________\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
